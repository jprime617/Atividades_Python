{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396d62a5",
   "metadata": {},
   "source": [
    "# Roteiro de Aula: Python para Análise de Dados\n",
    "\n",
    "## Guias Gerais\n",
    "- Retomar conceitos de algoritmos e estruturas de dados\n",
    "- Demonstrar instalação das bibliotecas pandas e numpy\n",
    "- Utilizar dataset real para exemplificar (emendas parlamentares)\n",
    "- Fazer uma análise exploratória dos dados, usando estatística básica (centralidade e dispersão)\n",
    "- Pandas x Numpy\n",
    "  - Altamente compatíveis, convivem em harmonia\n",
    "  - Processamento Numérico: Numpy\n",
    "  - Manipulação de dados: Pandas\n",
    "\n",
    "\n",
    "Bibliografia principal (Open Access): https://wesmckinney.com/book/\n",
    "\n",
    "Uma experiência de análise de dados com visualização: \n",
    "\n",
    "![Visualização: Bolha da IA?](ai_bubble_viz.webp)\n",
    "\n",
    "Uma interpretação possível pode ser encontrada no post do substack:\n",
    "https://broligarchy.substack.com/p/the-great-ai-bubble.\n",
    "\n",
    "\n",
    "E o gráfico abaixo, que história ele conta?\n",
    "\n",
    "![Taxa de reincidência de prisoneiros (1994)](prison_bad_viz.jpg)\n",
    "\n",
    "\n",
    "Quais são os principais pecados cometidos pelo criador desse gráfico?\n",
    "Vocês enxergam técnicas mais apropriadas para gerar a visualização desse cenário?\n",
    "\n",
    "### Interpretadores \n",
    "\n",
    "Revisar as metodologias de execução de código python utilizadas nos semestres anteriores.\n",
    "\n",
    "Ilustrar a execução de código no modelo escreve-compila, usando um editor de texto e executando via terminal. O mesmo pode ser feito para o notebook.\n",
    "\n",
    "Apresentar o interpretador python via linha de comando, destacando os benefícios desse uso.\n",
    "\n",
    "Introdução do interpretador ipython - \n",
    "``` pip install ipython ```\n",
    "\n",
    "Vantagens:\n",
    "- Possui um terminal do SO integrado ao interpretador python, facilitando a iteração e manipulação de datasets em tempo de desenvolvimento/exploração;\n",
    "- Tab-completion: o terminal ipython possui auto-complete vinculado ao namespace sob o cursor, buscando variáveis, objetos e funções registradas. Também funciona para arquivos e elementos da área de trabalho do SO, agilizando a exploração inicial de datasets;\n",
    "- Introspecção: utilizando o caractere ? após um nome de variável, biblioteca ou função exibe detalhes sobre o objeto diretamente no terminal.\n",
    "- Stacktraces: ao executar um script python pelo interpretador `%run script.py` e encontrar uma exceção, o ipython exibe um stacktrace mais detalhado do que o interpretador padrão\n",
    "\n",
    "Utilizar %history para recuperar o histórico de comandos do interpretador\n",
    "Utilizar %load para carregar um script python\n",
    "\n",
    "Exemplo prático: Acessar arquivos em locais distintos rapidamente:\n",
    "```\n",
    "cd code\n",
    "ls\n",
    "cd cd unisenai_BI_DV/\n",
    "cd unisenai_BI_DV/\n",
    "ls\n",
    "cd \"Aula 2 - Python para Análise de Dados\"\n",
    "ls\n",
    "import pandas as pd\n",
    "csv = pd.read_csv(\"EmendasParlamentares.csv\")\n",
    "csv = pd.read_csv(\"EmendasParlamentares.csv\", encoding='iso-8859-1',sep=';')\n",
    "csv\n",
    "csv['Ano da Emenda']\n",
    "csv[csv['Ano da Emenda']>2024]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1318c",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "\n",
    "Principal biblioteca para computação numérica em python. O nome deriva de Numerical Python. \n",
    "É formalmente reconhecida como a principal interface para armazenamento e troca de dados com sua implementação de arrays.\n",
    "\n",
    "Sua principal força é na implementação eficiente de estruturas de arrays multidimensionais com expressões vetoriais embutidas. Pareada com operações matemáticas de alta performance (velocidade) voltadas à manipulação de arrays completos, a biblioteca assumiu destaque . Implementa também capacidades de álgebra linear, geração de números aleatórios e transformadas de Fourier. \n",
    "\n",
    "\n",
    "### Conceitos\n",
    "\n",
    "ndarray: array multidimensional\n",
    "\n",
    "Implementação para vetores de n-dimensões, o ndarray é um container robusto que implementa eficiência de memória e performance para operações vetoriais. Um dos grandes destaques do objeto é a expressão de operações aritméticas de forma direta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Criação de um ndarray\n",
    "data = np.array([1,2,3,4,5])\n",
    "data_doubled = data * 2\n",
    "data_summed = data + data_doubled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bdce17",
   "metadata": {},
   "source": [
    "\n",
    "Características:\n",
    "- Container de dados **homogêneos** (todos os dados devem possuir o mesmo tipo)\n",
    "- Shape: descreve a forma do array através de uma tupla contendo o tamanho de cada dimensão\n",
    "- Dtype: tipo dos dados contidos no array. Os tipos de dados do numpy possuem maior granularidade do que os tipos padrão do pyhton (por ex: int32, int64 vs int) \n",
    "\n",
    "A eficiência da implementação de arrays do numpy pode ser demonstrada pelos comandos a seguir.\n",
    "\n",
    "```  \n",
    "In [10]: %timeit my_arr2 = my_arr * 2\n",
    "309 us +- 7.48 us per loop (mean +- std. dev. of 7 runs, 1000 loops each)\n",
    " In [11]: %timeit my_list2 = [x * 2 for x in my_list]\n",
    "46.4 ms +- 526 us per loop (mean +- std. dev. of 7 runs, 10 loops each)\n",
    "```\n",
    "\n",
    "#### Inicializando Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ddcf46",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'zeroes'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m array4 = np.array([[\u001b[32m10\u001b[39m,\u001b[32m11\u001b[39m],[\u001b[32m12\u001b[39m,\u001b[32m13\u001b[39m]]) \u001b[38;5;66;03m# Matriz 2x2\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m#Inicialização zerada ou unária\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m zeroes = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeroes\u001b[49m(\u001b[32m10\u001b[39m) \u001b[38;5;66;03m# Array de 10 elementos, preenchido com 0\u001b[39;00m\n\u001b[32m      9\u001b[39m zeroes2 = np.zeroes((\u001b[32m3\u001b[39m,\u001b[32m5\u001b[39m)) \u001b[38;5;66;03m# Matriz 3x5, preenchida com 0\u001b[39;00m\n\u001b[32m     10\u001b[39m ones = np.ones(\u001b[32m5\u001b[39m) \u001b[38;5;66;03m# Array de 5 posições, preenchido com 1\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eric.zancanaro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\__init__.py:808\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchar\u001b[39;00m\n\u001b[32m    806\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m char.chararray\n\u001b[32m--> \u001b[39m\u001b[32m808\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'numpy' has no attribute 'zeroes'"
     ]
    }
   ],
   "source": [
    "#Inicialização com dados existentes\n",
    "array = np.array([1,2,3])\n",
    "array2 = np.array({4,5,6})\n",
    "array3 = np.array((7,8)) # Qualquer objeto tipo sequência\n",
    "array4 = np.array([[10,11],[12,13]]) # Matriz 2x2\n",
    "\n",
    "#Inicialização zerada ou unária\n",
    "zeroes = np.zeros(10) # Array de 10 elementos, preenchido com 0\n",
    "zeroes2 = np.zeros((3,5)) # Matriz 3x5, preenchida com 0\n",
    "ones = np.ones(5) # Array de 5 posições, preenchido com 1\n",
    "\n",
    "#Inicialização \"vazia\"\n",
    "empty = np.empty((1,2)) #Matriz 1x2, com elementos não inicializados. Cuidado com o lixo!\n",
    "\n",
    "#Inicialização por intervalos\n",
    "range = np.arange(15) # Array com 15 elentos, igualmente distribuídos entre 0 e 15\n",
    "range_10_10to20 = np.arange(10,20) # Array com 10 elementos, entre 10 e 20 [10, 20) \n",
    "range_5_10to20 = np.arange(10,20,2) # Array com 5 elementos, entre 10 e 20 [10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b28789e",
   "metadata": {},
   "source": [
    "#### Aritmética\n",
    "\n",
    "Operações aritméticas básicas entre arrays de mesmas dimensões são aplicadas elemento a elemento. É possível aplicar operações entre 2 arrays com dimensões diferentes através de *broadcasting* (mais complexo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc244bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.arange(10)\n",
    "#Aplica a soma a cada elemento do vetor\n",
    "array2 = array + 10\n",
    "# Multiplicação elemento a elemento\n",
    "array3 = array * array2\n",
    "# Subtração elemento a elemento\n",
    "array4 = array - array2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77523da",
   "metadata": {},
   "source": [
    "Também é possível realizar operações booleanas. Nesse caso, o retorno é um array contendo apenas valores booleanos, indicando o resultado da operação para cada elemento dos vetores originais.\n",
    "\n",
    "#### Indícies e fatias (slices)\n",
    "\n",
    "Elementos podem ser acessados da mesma maneira que arrays python, utilizando índices com base 0. Numpy também provê a sintaxe familiar de slices para obter um subconjunto dos dados. Um detalhe essencial aqui é que os slices funcionam como uma janela para os dados originais, sem gerar uma cópia como no array python. Isso significa que os dados originais podem ser manipulados através dos slices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f5769",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.arange(10)\n",
    "\n",
    "# Acesso de leitura\n",
    "el0 = array[0]\n",
    "# Modificação de elemento do array\n",
    "array[5] = 50\n",
    "\n",
    "# Subconjunto dos dados\n",
    "slice = array[5:8]\n",
    "# Alteração do elemento na posição 5 do array original\n",
    "slice[0] = 60\n",
    "# Broadcasting: atribui o valor 45 para **todas** as posições da fatia\n",
    "slice = 45 \n",
    "# Alteração dos valores de todo o array\n",
    "array[:] = 0\n",
    "\n",
    "#Cópias devem ser explícitas:\n",
    "sep = array[5:8].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755b4345",
   "metadata": {},
   "source": [
    "Para arrays multidimensionais, o acesso pode ser feito a cada dimensão. Uma forma de se entender arrays multimensionais é compreender cada dimensão como um \"eixo\" em uma representação gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da024f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "\n",
    "# Acesso via índices recursivos\n",
    "num6 = arr3d[0][1][2]\n",
    "# Equivalente ao acesso via lista de índices!\n",
    "num6 = arr3d[0, 1, 2]\n",
    "\n",
    "# A primeira posição do array 3D é um array de duas dimensões!\n",
    "arr2d = arr3d[0]\n",
    "# O mesmo é válido recursivamente!\n",
    "arr1d = arr2d[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b89085",
   "metadata": {},
   "source": [
    "Fatias de arrays multimensionais são mais complicadas. A sintaxe de slices atua em cada \"eixo\" do array de múltiplas dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378b0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "\n",
    "# A fatia conterá 2 arrays de 2 dimensões!\n",
    "slice = arr3d[0:2]\n",
    "\n",
    "arr2d = arr3d[0]\n",
    "# A fatia traz as duas primeiras \"linhas\" da matriz bidimensional\n",
    "slice2 = arr2d[0:2]\n",
    "\n",
    "#A sintaxe de slices pode ser combinada em uma única expressão:\n",
    "slice3 = arr3d[0:2, 0:2]\n",
    "\n",
    "#Slices podem ser combinados com índices!\n",
    "slice4 = arr3d[0, 0:2]\n",
    "\n",
    "#Como selecionar a as 2 primeiras colunas da primeira linha de um array bidimensional?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966183b8",
   "metadata": {},
   "source": [
    "##### Indexação Booleana\n",
    "\n",
    "Demonstramos acima que operações booleanas entre arrays numpy resultam em arrays booleanos. Uma propriedade útil destes arrays booleanos é que eles servem como \"máscara\" para selecionar elementos específicos dentro do array. Isso é feito utilizando o vetor booleano no lugar do índice:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5,6])\n",
    "# Operações booleanas retornam um array booleano\n",
    "b = a < 3\n",
    "\n",
    "# Um array booleano pode ser utilizado como \"máscara\" para indexar os dados:\n",
    "a[b] # Seleciona todos os elementos de a menores que 3 \n",
    "\n",
    "#Operações booleanas podem ser encadeadas com os operadores lógicos & e |\n",
    "a[ (a < 3)  & (a >= 0)] # Elementos de a entre 0 e 3 (cópia)\n",
    "\n",
    "c = np.array(['joão','josé','maria','josé','joana','pablo'])\n",
    "a[c == 'josé']\n",
    "c[a < 6 ]\n",
    "\n",
    "# Negação pode ser feita via condição ou pelo operador ~\n",
    "a[~(c=='josé')]\n",
    "a[ c!='josé']\n",
    "\n",
    "#Elementos podem ser alterados via indexação booleana!\n",
    "a[a < 3 ] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ca78bf",
   "metadata": {},
   "source": [
    "Só é possível indexar via array booleano se ambos forem do mesmo tamanho. Um exemplo de caso de uso é no processamento de imagens:\n",
    "  \n",
    "  1. Uma imagem pode ser representada em código python através de um array bidimensional. Cada elemento é um array com 3 posições, representando as cores no formato RGB;\n",
    "  2. Através do processamento podemos gerar uma versão em escala de cinza desta imagem, representada por um array bidimensional, onde cada elemento é a intensidade do cinza (0 a 255);\n",
    "  3. Podemos utilizar esta segunda imagem como uma máscara para extrair detalhes da imagem original utilizando a indexação booleana!\n",
    "\n",
    "Demonstrar `exemplo_processamento_imagem.py`\n",
    "\n",
    "### Aplicações\n",
    "\n",
    "#### Gerando distribuições pseudoaleatórias\n",
    "\n",
    "A biblioteca contém funcionalidades para a geração de valores pseudoaleatórios em larga escala. Essa funcionalidade é útil quando precisamos escolher uma amostra dos dados, por exemplo, de acordo com uma determinada distribuição de probabilidade. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8df6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz 4x4 contendo amostra de dados aleatórios na distribuição normal\n",
    "sample = np.random.standard_normal(size=(4,4))\n",
    "\n",
    "#Gerador padrãos\n",
    "rng = np.random.default_rng()\n",
    "# Valores aleatórios inteiros entre 1 e 40\n",
    "sample = rng.integers(low=1, high=40, size=(4,4))\n",
    "\n",
    "#Distribuição de probabilidade uniforme\n",
    "sample = rng.uniform(size=(3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c817b2",
   "metadata": {},
   "source": [
    "#### Processando dados vetoriais\n",
    "\n",
    "As operações vetorizadas da biblioteca não se resumem aos operadores algébricos. O processamento de todos elementos de um array é simplificado pela utilização de funções universais (*ufuncs*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aafbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eric.zancanaro\\AppData\\Local\\Temp\\ipykernel_2676\\2389027181.py:5: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = np.sqrt(arr)\n",
      "C:\\Users\\eric.zancanaro\\AppData\\Local\\Temp\\ipykernel_2676\\2389027181.py:10: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result[i] = np.sqrt(arr[i])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.07357467,  1.33401368, -0.36736935, -0.53248286,  0.17702416,\n",
       "        0.57500472,  0.05942853,  1.45190355])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "arr = rng.standard_normal(8)\n",
    "arr2 = rng.standard_normal(8)\n",
    "\n",
    "# Retorna um novo array, contendo a raiz de cada elemento\n",
    "result = np.sqrt(arr)\n",
    "\n",
    "#Equivalente ao loop\n",
    "result = np.zeros(8)\n",
    "for i in range(0,8):\n",
    "  result[i] = np.sqrt(arr[i])\n",
    "\n",
    "#Recebe 2 arrays, retorna um array com o maior valor de cada posição\n",
    "max = np.maximum(arr, arr2)\n",
    "\n",
    "# Recebe 1 array de floats, retorna 2 arrays: parte fracionária e inteira de cada elemento\n",
    "frac_part, int_part = np.modf(arr)\n",
    "\n",
    "# O argumento out é opcional, podendo ser utilizado para atribuir o resultado a um array existente\n",
    "np.maximum(arr, arr2, out=arr) #Modifica o array arr com o resultado da operação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3e127",
   "metadata": {},
   "source": [
    "Consulte as funções disponíveis na [Documentação](https://numpy.org/doc/stable/reference/ufuncs.html#available-ufuncs).\n",
    "\n",
    "Além das transformações vetoriais, operações de agregação também são fornecidas pela biblioteca. Essas operações são de uso comum na estatística e matemática:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12bb66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rng.standard_normal(8)\n",
    "arr2d = rng.standard_normal((5, 4))\n",
    "\n",
    "# Calcula a média dos elementos do array\n",
    "media = np.mean(arr)\n",
    "# Soma de todos os elementos\n",
    "soma = np.sum(arr2d) \n",
    "\n",
    "# Também é possível somar apenas 1 \"eixo\" de arrays multidimensionais.\n",
    "# Estes métodos resultam em um novo array \n",
    "soma_col = np.sum(arr2d, axis=1) # Soma dos elementos por coluna\n",
    "soma_lin = np.sum(arr2d, axis=0) # Soma dos elementos por linhas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d025913",
   "metadata": {},
   "source": [
    "O processamento vetorial nos permite expressar tarefas de processamento de dados de maneiras mais concisas, evitando a criação de loops explícitos. Devido às otimizações da biblioteca, essas expressões são também mais eficientes em termos de uso de memória e velocidade.\n",
    "\n",
    "Por exemplo, uma tarefa comum no processamento de dados para machine learning é a normalização de valores em um intervalo pré-determinado. Uma técnica comum é a padronização em torno da z-score, cuja fórmula matemática é z = (x - mu)/ sigma\n",
    "\n",
    "mu=média, sigma=desvio padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf39bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(100, 100)\n",
    "\n",
    "#Cálculo das métricas estatísticas. Recebem um array e retornam um escalar\n",
    "mu = np.mean(data) # média\n",
    "sigma = np.std(data) # desvio padrão\n",
    "\n",
    "# Operação vetorizada\n",
    "z_scores = (data - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0070bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemplo de detecção de bordas extraído de https://stackoverflow.com/questions/63036809/how-do-i-use-only-numpy-to-apply-filters-onto-images\n",
    "from PIL import Image\n",
    "# Create a test image with a white square on black\n",
    "rect = np.zeros((200,200), dtype=np.uint8)\n",
    "rect[40:-40,40:-40] = 255\n",
    "\n",
    "# Create a test image with a white circle on black\n",
    "xx, yy = np.mgrid[:200, :200]\n",
    "circle = (xx - 100) ** 2 + (yy - 100) ** 2\n",
    "circle = (circle<4096).astype(np.uint8)*255\n",
    "\n",
    "# Concatenate side-by-side to make our test image\n",
    "im = np.hstack((rect,circle))\n",
    "Image.fromarray(im).show()\n",
    "# Calculate horizontal differences only finding increasing brightnesses\n",
    "d = im[:,1:] - im[:,0:-1]\n",
    "Image.fromarray(d).show()\n",
    "# Calculate horizontal differences finding increasing or decreasing brightnesses\n",
    "d = np.abs(im[:,1:].astype(np.int16) - im[:,0:-1].astype(np.int16))\n",
    "Image.fromarray(d).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2190257f",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Principal biblioteca para o processamento de dados *heterogêneos* em python. Utiliza muitas das convenções estabelecidas pela processamento de arrays do numpy. \n",
    "\n",
    "### Conceitos\n",
    "\n",
    "#### Series\n",
    "  Uma série pandas é uma coleção de valores de um único tipo (numérico, strings, etc..), associado a um índice composto por um array de identificadores. O caso mais simples gera um índice automático composto por inteiros iniciados em 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437caabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Série com índice default ([\"0\",\"1\",\"2\",\"3\"])\n",
    "serie = pd.Series([1,2,3,4]) \n",
    "\n",
    "# Série com identificadores explícitos\n",
    "serie_id = pd.Series([1,2,3,4], index=[\"a\",\"b\",\"c\",\"d\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d979fa7c",
   "metadata": {},
   "source": [
    "O índice da série é utilizado para acessar os elementos de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b141a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "a    1\n",
      "c    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(serie[0])\n",
    "print(serie_id[\"a\"])\n",
    "#Também é possível selecionar múltiplos elementos:\n",
    "print(serie_id[[\"a\",\"c\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b6e706",
   "metadata": {},
   "source": [
    "Nas séries, o índice é preservado na transformação ou filtro dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16d89cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção dos elementos > 0\n",
    "print( serie_id[serie_id > 0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaff85b7",
   "metadata": {},
   "source": [
    "As séries pandas são compatíveis com operações numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9657e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(serie_id))\n",
    "print(np.sqrt(serie_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05096bb",
   "metadata": {},
   "source": [
    "Também é possível criar séries indexadas a partir de um dicionário python pre-existente. Nesse caso, o índice será composto pelas chaves do dicionário:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "notas = {\"Huguinho\":9.2, \"Zezinho\":7.6, \"Luizinho\":8.3, \"Leticia\":9.5}\n",
    "notas2 = {\"Huguinho\":5.6, \"Zezinho\":7.0, \"Luizinho\":5.3, \"Leticia\":9.0}\n",
    "\n",
    "# A ordenação depende da ordem de inserção das chaves no dicionário!\n",
    "n_serie = pd.Series(notas) \n",
    "print(n_serie)\n",
    "\n",
    "# Para alterar a ordem da série, ou selecionar campos específicos, podemos passar um array ordenado\n",
    "n_serie2 = pd.Series(notas2, index=[\"Huguinho\",\"Leticia\",\"Zezinho\",\"Xavier\"]) \n",
    "print(n_serie2) #NaN representa valor não existente (Not a Number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a0cf1",
   "metadata": {},
   "source": [
    "\n",
    "Operações de múltiplas séries são automaticamente alinhadas pelos identificadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "soma = n_serie + n_serie2\n",
    "print(soma)\n",
    "medias = soma / 2\n",
    "print(medias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a5fbf8",
   "metadata": {},
   "source": [
    "#### DataFrames\n",
    "\n",
    "Utilizados para representar dados tabulares na biblioteca, os dataframes são compostos por uma coleção de colunas nomeadas, cada uma delas de um tipo específico. Associado ao dataframe estão 2 índices: 1 índice para as linhas e 1 índice para as colunas. De forma abrangente, um dataframe é um conjunto de séries que compartilha o mesmo índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4276bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = {\"nome\":[\"Huguinho\",\"Leticia\",\"Luizinho\",\"Zezinho\"],\n",
    "  \"matricula\":[10222, 10223, 10224, 10225],\n",
    "  \"n_1\":[7.5, 8.2, 3.4, 9.5],\n",
    "  \"n_2\":[2.3, 8.0, 7.6, 9.0],\n",
    "}\n",
    "\n",
    "# As colunas são indexadas pelas chaves do dicionário. Linhas tem o índice numérico padrão\n",
    "frame = pd.DataFrame(dados)\n",
    "\n",
    "# Podemos usar uma coluna específica como índice:\n",
    "frame.set_index('matricula', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3a4e0e",
   "metadata": {},
   "source": [
    "\n",
    "O acesso via índices é utilizado para recuperar as colunas do dataframe no formato de séries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "serie_n1 = frame[\"n_1\"]\n",
    "print(serie_n1)\n",
    "#Ou equivalente:\n",
    "print(frame.n_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d1012e",
   "metadata": {},
   "source": [
    "Para acessar linhas devemos utilizar os métodos de localização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e15a0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_2676\\930603823.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# iloc é usado para buscar pela posição da linha (iniciado em 0)\u001b[39;00m\n\u001b[32m      4\u001b[39m frame.iloc[\u001b[32m1\u001b[39m]\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Podemos retornar apenas colunas específicas com este operador:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m frame.loc([\u001b[32m10223\u001b[39m, [\u001b[33m\"n_1\"\u001b[39m,\u001b[33m\"n_2\"\u001b[39m]]) \u001b[38;5;66;03m# Seleciona n1 e n2 da matrícula 10223\u001b[39;00m\n\u001b[32m      8\u001b[39m frame.loc([[\u001b[32m10223\u001b[39m,\u001b[32m10224\u001b[39m], [\u001b[33m\"n_1\"\u001b[39m,\u001b[33m\"n_2\"\u001b[39m]]) \u001b[38;5;66;03m# Seleciona n1 e n2 das matrículas 10223 e 10224\u001b[39;00m\n",
      "\u001b[32mc:\\Users\\eric.zancanaro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis)\u001b[39m\n\u001b[32m    735\u001b[39m         \u001b[38;5;66;03m# we need to return a copy of ourselves\u001b[39;00m\n\u001b[32m    736\u001b[39m         new_self = type(self)(self.name, self.obj)\n\u001b[32m    737\u001b[39m \n\u001b[32m    738\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m             axis_int_none = self.obj._get_axis_number(axis)\n\u001b[32m    740\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    741\u001b[39m             axis_int_none = axis\n\u001b[32m    742\u001b[39m         new_self.axis = axis_int_none\n",
      "\u001b[32mc:\\Users\\eric.zancanaro\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(cls, axis)\u001b[39m\n\u001b[32m    576\u001b[39m     @classmethod\n\u001b[32m    577\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _get_axis_number(cls, axis: Axis) -> AxisInt:\n\u001b[32m    578\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    579\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m cls._AXIS_TO_AXIS_NUMBER[axis]\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m KeyError:\n\u001b[32m    581\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(f\"No axis named {axis} for object type {cls.__name__}\")\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "# loc é utilizado para buscar pelo identificador da linha\n",
    "frame.loc[10223]\n",
    "# iloc é usado para buscar pela posição da linha (iniciado em 0)\n",
    "frame.iloc[1]\n",
    "\n",
    "# Podemos retornar apenas colunas específicas com este operador:\n",
    "frame.loc([10223, [\"n_1\",\"n_2\"]]) # Seleciona n1 e n2 da matrícula 10223 \n",
    "frame.loc([[10223,10224], [\"n_1\",\"n_2\"]]) # Seleciona n1 e n2 das matrículas 10223 e 10224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede9951c",
   "metadata": {},
   "source": [
    "Para adicionar ou modificar colunas no dataframe, podemos utilizar a atribuição simples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22b8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desde que o array possua o tamanho correto\n",
    "frame[\"n_1\"] = np.array([2.0,3.4,5.0,9.8])\n",
    "\n",
    "# Se o valor atribuído é uma série, as modificações são alinhadas ao índice\n",
    "# Valores ausentes são atribuídos NaN!\n",
    "frame[\"n_1\"] = pd.Series([7.5, 8.2, 7.9], index=[10222, 10223, 10224])\n",
    "\n",
    "# Para criar uma nova coluna, podemos atribuir a série a um índice inexistente\n",
    "frame[\"frequencia\"] = pd.Series([0.5, 1.0, 0.85, 0.9], index=[10222, 10223, 10224, 10225])\n",
    "\n",
    "# Podemos criar colunas com base no resultado de operações vetoriais:\n",
    "frame[\"media\"] = (frame[\"n_1\"] + frame[\"n_2\"]) / 2\n",
    "frame[\"reprovado_freq\"] = frame[\"frequencia\"] < 0.75\n",
    "\n",
    "# A exclusão de valores é feita pelo método drop\n",
    "frame.drop(index=[10222,10223]) #Exclui as linhas\n",
    "frame.drop(column=\"media\") #Exclui a coluna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49450ee",
   "metadata": {},
   "source": [
    "\n",
    "Uma documentação extensa das maneiras de criar um dataframe está disponível no [link](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)\n",
    "\n",
    "### Aplicações\n",
    "\n",
    "Series e dataframes são utilizados para a validação, análise e processamento de dados tabulares via scripts python. \n",
    "\n",
    "Podemos facilmente filtrar os valores das séreies/frames utilizando a indexação por array booleanos como no numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddaa081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A indexação pode ser utilizada como no padrão numpy para filtrar os valores!\n",
    "frame[frame[\"reprovado_freq\"]] # Traz os alunos reprovados por frequência\n",
    "frame[frame[\"media\"] < 6] # Traz os alunos reprovados por nota"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bda16f",
   "metadata": {},
   "source": [
    "\n",
    "Um detalhe importante da operação entre series/dataframes é o tratamento de valores ausentes. Se fazemos uma operação entre 2 séries/dataframes, o resultado é a união dos índices das estruturas operadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = {\"Huguinho\":9.2, \"Zezinho\":7.6, \"Luizinho\":8.3, \"Leticia\":9.5}\n",
    "n2 = {\"Huguinho\":5.6, \"Zezinho\":7.0, \"Leticia\":9.0}\n",
    "\n",
    "s1 = pd.Series(n1)\n",
    "s2 = pd.Series(n2)\n",
    "\n",
    "# A soma é alinhada pelos índices, porém Luizinho existe apenas em n1!\n",
    "soma = s1 + s2\n",
    "\n",
    "# O valor resultante da soma é NaN para Luizinho!\n",
    "print(soma)\n",
    "\n",
    "#O método de adição dos objetos provê um parâmetro opcional para substituir valores inexistentes:\n",
    "soma = s1.add(s2, fill_value=0.0)\n",
    "print(soma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9270123f",
   "metadata": {},
   "source": [
    "\n",
    "É importante tratar esses casos com mecanismos de limpeza de dados antes de realizar as operações entre os dados. \n",
    "\n",
    "As funções universais do numpy também são aplicáveis aos objetos do pandas. Um cuidado especial deve ser tomado quando os dataframes possuem dados heterogêneos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f98133e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n1_serie = frame[\"n_1\"]\n",
    "np.round(n1_serie)\n",
    "\n",
    "#Erro pois o frame contém dados do tipo string, que não possuem sqrt definida! \n",
    "np.sqrt(frame)\n",
    "# Ok pois n_1 e n_2 são tipos numéricos\n",
    "np.sqrt(frame[[\"n_1\",\"n_2\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879026e1",
   "metadata": {},
   "source": [
    "\n",
    "Também podemos aplicar funções customizadas a cada linha, coluna, ou elemento de um dataframe usando os métodos apply e applymap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c201d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def max_val(x):\n",
    "    return x.max() \n",
    "\n",
    "#Retorna maior valor de cada coluna\n",
    "frame.apply(max_val)\n",
    "\n",
    "#Retorna maior valor de cada linha. Cuidado quando as colunas tem tipos diferentes!\n",
    "frame[[\"n_1\",\"n_2\"]].apply(max_val, axis='columns')\n",
    "\n",
    "def append_(x):\n",
    "  return f\"{x}_\"\n",
    "\n",
    "#Para aplicar uma função em cada elemento usamos applymap\n",
    "frame.applymap(append_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1f4740",
   "metadata": {},
   "source": [
    "### Exercícios\n",
    "\n",
    "Utilizando pandas, processe o arquivo **EmendasParlamentares.csv**. \n",
    "Deste arquivo, obtenha as respostas para as perguntas a seguir:\n",
    "\n",
    "1. Qual o valor total pago em emendas por ano? (Utiliza: groupby e sum na coluna Ano da Emenda e Valor Pago).\n",
    "2. Qual é a média e o desvio padrão dos valores empenhados por região do Brasil? \n",
    "3. Quais são os 10 autores que mais destinaram recursos (valor empenhado) na história do dataset? \n",
    "4. Quantas emendas foram destinadas para o estado de Santa Catarina?\n",
    "5. Destas emendas, quais municípios se destacam no recebimento dos recursos por tipo?\n",
    "\n",
    "6. Existem emendas onde o valor liquidado é significativamente diferente do valor pago? \n",
    "7. Qual o percentual de recursos que ficaram como \"Restos a Pagar Cancelados\" em relação ao total empenhado por ano? \n",
    "\n",
    "8. Qual é a Subfunção mais comum para cada Região do país? \n",
    "\n",
    "9. Existem linhas com Cdigo Municpio IBGE ausente? Como isso afeta a análise por localidade? \n",
    "10. O campo Município possui nomes duplicados com grafias diferentes (ex: acentuação)? \n",
    "\n",
    "O exemplo abaixo ilustra como calcular a \"Eficiência no Pagamento\": a relação entre o valor pago e o valor empenhado(reservado) para a emenda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ed5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eric.zancanaro\\AppData\\Local\\Temp\\ipykernel_2676\\1734061841.py:4: DtypeWarning: Columns (0,3,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"EmendasParlamentares.csv\",encoding=\"iso-8859-1\",sep=';')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Nome do Autor da Emenda\n",
       "COMISSAO DE DEFESA DO CONSUMIDOR - CDC        100.0\n",
       "COMISSAO DE LEGISLACAO PARTICIPATIVA - CLP    100.0\n",
       "DEP. ROSEANA SARNEY                           100.0\n",
       "CLAUDIO PUTY                                  100.0\n",
       "COMISSAO SENADO DO FUTURO - CSF               100.0\n",
       "                                              ...  \n",
       "CYRO MIRANDA                                    0.0\n",
       "DALVA FIGUEIREDO                                0.0\n",
       "COMISSAO DO ESPORTE - CESPO                     0.0\n",
       "COMISSAO DE TURISMO - CTUR                      0.0\n",
       "ACELINO POPO                                    0.0\n",
       "Name: Eficiencia_Pagamento, Length: 1599, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"EmendasParlamentares.csv\",encoding=\"iso-8859-1\",sep=';')\n",
    "#Tentamos converter diretamente. Importante, os valores fracionados na planilha estão usando , como separador e pandas espera .\n",
    "df['Valor Empenhado'] = df['Valor Empenhado'].str.replace(',','.')\n",
    "df['Valor Pago'] = df['Valor Pago'].str.replace(',','.')\n",
    "df['Valor Empenhado'] = pd.to_numeric(df['Valor Empenhado'])\n",
    "df['Valor Pago'] = pd.to_numeric(df['Valor Pago'])\n",
    "\n",
    "# Exemplo de criação de atributo (Feature Engineering)\n",
    "df['Eficiencia_Pagamento'] = (df['Valor Pago'] / df['Valor Empenhado']) * 100\n",
    "\n",
    "# Ranking dos autores mais eficientes em liberar recursos\n",
    "ranking = df.groupby('Nome do Autor da Emenda')['Eficiencia_Pagamento'].mean().sort_values(ascending=False)\n",
    "ranking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
